Metadata-Version: 2.4
Name: ux-writer-assistant-backend
Version: 0.1.0
Summary: FastAPI backend for UX Writer Assistant (lab, file-first + RAG-ready)
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: fastapi>=0.111.0
Requires-Dist: uvicorn>=0.30.0
Requires-Dist: pydantic>=2.8.0
Requires-Dist: pydantic-settings>=2.2.1
Requires-Dist: python-multipart>=0.0.9
Requires-Dist: pyyaml>=6.0
Requires-Dist: openai>=1.30.0
Requires-Dist: sqlalchemy>=2.0.30
Requires-Dist: psycopg[binary]>=3.1.0
Requires-Dist: alembic>=1.13.1
Requires-Dist: qdrant-client>=1.9.1
Requires-Dist: trio>=0.25.0
Requires-Dist: numpy>=1.26.0
Requires-Dist: onnxruntime>=1.17.0
Requires-Dist: tokenizers>=0.15.2
Provides-Extra: dev
Requires-Dist: pytest>=8.3.0; extra == "dev"
Requires-Dist: httpx>=0.27.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.23.6; extra == "dev"
Requires-Dist: ruff>=0.5.0; extra == "dev"
Requires-Dist: trio>=0.25.0; extra == "dev"

# UX Writer Assistant — Backend (FastAPI)

This is a **file-first** lab backend to test ingest/retrieve/translate flows. Day 2부터는
PostgreSQL/Qdrant 기반 프로덕션 구조를 준비하기 위해 ORM 모델과 설정 스캐폴드를 포함한다.

## Quickstart (with `uv`)
```bash
# from repo root
cd backend
uv venv .venv
uv pip install -e .[dev]
uv run uvicorn app.main:app --reload --port 8000
```

If you don't use `uv`:
```bash
python -m venv .venv
source .venv/bin/activate  # (Windows: .venv\Scripts\activate)
pip install -e .[dev]
uvicorn app.main:app --reload --port 8000
```

## Endpoints
- `POST /v1/ingest` — load files from `../data/input`, persist them to Postgres/Qdrant, and refresh in-memory indices
- `POST /v1/retrieve` — simple BM25-ish/keyword retrieval (file-first)
- `POST /v1/translate` — LLM-backed translation with optional guardrails and retrieval context

추가 예정:
- `/v1/requests`, `/v1/drafts`, `/v1/approvals` 등 워크플로우 API (ORM 기반)
- `/v1/exports`, `/v1/search` (Day 7~8 계획)

## Data Layout
```
data/
  input/
    context.jsonl
    glossary.csv
    style_corpus.csv
    style_rules.yaml
  results/
  history/
  logs/
```

> NOTE: This is a lab scaffold. Retrieval은 Day 2에서 Qdrant 설정/컬렉션 스키마를 코드로 정의했으며,
> 이후 하이브리드 검색 및 rerank 서비스를 연동할 예정이다.

## Database & Vector Store Setup (Day 2 Preview)

- `app/db/models.py`: 요청/초안/버전/승인/Export/Guardrail/Audit 테이블 ORM 정의.
- `app/db/session.py`: SQLAlchemy 엔진 및 세션 관리. 기본값은 `sqlite:///./ux_writer_lab.db`.
- 환경 변수
  - `DATABASE_URL` — e.g. `postgresql+psycopg://user:pass@localhost:5432/ux_writer`.
  - `QDRANT_HOST`, `QDRANT_PORT`, `QDRANT_API_KEY`, `QDRANT_USE_GRPC`.
  - `EMBEDDING_MODEL`, `EMBEDDING_PRECISION`, `EMBEDDING_BACKEND` (`stub` or `onnx`), `EMBEDDING_ONNX_PATH`.
- RAG 기본 컬렉션은 `app/services/rag/config.py`에서 선언하며, 스타일 가이드/확정 문구/용어집/컨텍스트 네 가지를 다룬다.

## Configuration

Copy `.env.example` to `.env` and provide your keys before running translation:

```bash
cp .env.example .env
# then edit .env to set LLM_API_KEY (and optional overrides)
```

Environment variables:
- `LLM_PROVIDER` — currently supports `openai`.
- `LLM_MODEL` — chat/completions model name, e.g. `gpt-4o-mini`.
- `LLM_API_KEY` — API key for the provider.
- `LLM_BASE_URL` — optional custom endpoint (for proxies/self-hosted).
- `LLM_TIMEOUT_SECONDS` — request timeout.
- `LLM_TEMPERATURE` — default sampling temperature.
- `EMBEDDING_BACKEND` — `stub` (default) uses deterministic vectors for tests, `onnx` enables FP16 bge-m3 inference via `onnxruntime`.
- `EMBEDDING_ONNX_PATH` — absolute path to the exported bge-m3 ONNX model (only when backend is `onnx`).
